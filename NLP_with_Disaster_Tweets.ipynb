{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP with Disaster Tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYcuwEtq6sWMRxKbPiMz9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajibmondal/Projects.NLP/blob/master/NLP_with_Disaster_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksKwt_OUfyNp",
        "colab_type": "code",
        "outputId": "1ee1231e-3502-4548-d161-62e5770413a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcghfLPCgJ1l",
        "colab_type": "code",
        "outputId": "0a2a5a5c-531f-42b9-ec3e-01bb1de4f6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGWKa1WAgRpL",
        "colab_type": "code",
        "outputId": "9a53dab0-adbe-4ed6-b340-d68a913248da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "source": [
        "pip install ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.17.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.10.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.38)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.3.0) (2.6.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp36-none-any.whl size=459038 sha256=f17443824d0eca5c873151d75c5a3a6367b4e17e6acfd974f968c1c860fcc947\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7kgfzw7o/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 2.3.0\n",
            "    Uninstalling transformers-2.3.0:\n",
            "      Successfully uninstalled transformers-2.3.0\n",
            "Successfully installed transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJbKJERNEa5P",
        "colab_type": "code",
        "outputId": "a39b37ef-72fa-4d55-b05e-a3621db5862f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3qD2EXhHzkL",
        "colab_type": "code",
        "outputId": "938bdd99-dbe7-4415-e5ad-7817ebb789ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfmp2s_wHm5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '/content/drive/My Drive/NLP/NLP_DATA/ NLP with Disaster Tweets/train.csv'\n",
        "test_path = '/content/drive/My Drive/NLP/NLP_DATA/ NLP with Disaster Tweets/test.csv'\n",
        "sample_submission_path = '/content/drive/My Drive/NLP/NLP_DATA/ NLP with Disaster Tweets/sample_submission.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bV5t8zTHSAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv((train_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNkI6PH7HUEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3sliHDOHm-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train = pd.read_csv(str((train_path/'train.csv')))\n",
        "test = pd.read_csv(test_path)\n",
        "sample_submission = pd.read_csv(sample_submission_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHtKSIq3HnEU",
        "colab_type": "code",
        "outputId": "2dd1e485-5c77-4ded-c012-30077f985814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape, test.shape, sample_submission.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 4), (3263, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAeiA_spMb-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXZ-RUfqMcE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 64\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "#model_type = 'xlnet'\n",
        "#pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM4SJDy9McKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNAqtEB4M4hb",
        "colab_type": "code",
        "outputId": "83883c0d-2fb1-4ff7-f151-ed9213707543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "model_class.pretrained_model_archive_map.keys()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0DkzujGMckQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sEkxr5VMc0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rLO--W6MdAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Q74s8DMdKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT_BUdxZMd1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsoLz3WyMdy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "  def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "    super(TransformersVocab, self).__init__(itos=[])\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "    \"Convent a list of tokens 't' to their ids. \"\n",
        "    return self.tokenizer.convert_tokens_to_ids(t)\n",
        "\n",
        "  def textify(self, nums:Collection[int], sep=' ') -> List [str]:\n",
        "    \"Convert a list of 'nums' to their tokens\"\n",
        "    nums = np.array(nums).tolist()\n",
        "    return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "\n",
        "  def __getstate__(self):\n",
        "    return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "  def __setstate__(self, state:dict):\n",
        "    self.itos = state['itos']\n",
        "    self.tokenizer = state['tokenizer']\n",
        "    self.stoi = collections.defaultdict(int, {v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWY45g1KMdv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def __getstate__(self):\n",
        "#   return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "# def __setstate__(self, state:dict):\n",
        "#   self.itos = state['itos']\n",
        "#   self.tokenizer = state['tokenizer']\n",
        "#   self.stoi = collections.defaultdict(int, {v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFKvs7TKMdt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Custom processor\n",
        "\n",
        "transformer_vocab = TransformersVocab(tokenizer=transformer_tokenizer)\n",
        "numericialize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericialize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R30pilKNMdrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " pad_first = bool(model_type in ['xlnet'])\n",
        " pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVQtVn5FMdpZ",
        "colab_type": "code",
        "outputId": "7f87f7d4-a0eb-4d44-8983-98a273644197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# 'Salut c est moi, Hello it s me'\n",
        "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
        "print(tokens)\n",
        "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)\n",
        "transformer_tokenizer.convert_ids_to_tokens(ids)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']\n",
            "[18111, 1182, 740, 3304, 7458, 118, 6, 20920, 24, 579, 162]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sal', 'ut', 'Ġc', 'Ġest', 'Ġmo', 'i', ',', 'ĠHello', 'Ġit', 'Ġs', 'Ġme']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wASjp9jT15Et",
        "colab_type": "code",
        "outputId": "d56bcf34-70d3-46de-8df6-8ff89c1c9c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "train[:200]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>274</td>\n",
              "      <td>ambulance</td>\n",
              "      <td>|| c h i c a g o ||</td>\n",
              "      <td>when you don't know which way an ambulance is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>276</td>\n",
              "      <td>ambulance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#reuters Twelve feared killed in Pakistani air...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>277</td>\n",
              "      <td>ambulance</td>\n",
              "      <td>L. A.</td>\n",
              "      <td>http://t.co/pWwpUm6RBj Twelve feared killed in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>279</td>\n",
              "      <td>ambulance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Why is there an ambulance right outside my work</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>280</td>\n",
              "      <td>ambulance</td>\n",
              "      <td>Canada</td>\n",
              "      <td>ÛÏ@LeoBlakeCarter: This dog thinks he's an am...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id    keyword  ...                                               text target\n",
              "0      1        NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1      4        NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2      5        NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3      6        NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4      7        NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "..   ...        ...  ...                                                ...    ...\n",
              "195  274  ambulance  ...  when you don't know which way an ambulance is ...      1\n",
              "196  276  ambulance  ...  #reuters Twelve feared killed in Pakistani air...      1\n",
              "197  277  ambulance  ...  http://t.co/pWwpUm6RBj Twelve feared killed in...      1\n",
              "198  279  ambulance  ...    Why is there an ambulance right outside my work      0\n",
              "199  280  ambulance  ...  ÛÏ@LeoBlakeCarter: This dog thinks he's an am...      0\n",
              "\n",
              "[200 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4bVN852PHC",
        "colab_type": "code",
        "outputId": "2f7237a3-11c8-4d67-8555-25a9e024254c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test[:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOOsxTN30bz5",
        "colab_type": "code",
        "outputId": "75218591-6550-45cd-b47c-dc27db6daa28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "databunch = (TextList.from_df(train,cols='text', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'target')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GypheghMdgN",
        "colab_type": "code",
        "outputId": "57c19af6-41d9-4499-f71d-a412a8b3adbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : <s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : Ġ. : ĠRT ĠDr A yes ha 4 : Ġ# India Ko M un Tor J aw ab Do Ċ Ċ Indian ĠArmy Ġki Â ī ÃĽ _ Ġhttp</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; ĠSE VER E ĠWE ATHER ĠB UL LET IN ĠNo . Ġ5 ĠFOR : ĠTY PH O ON ĠÂ ī ÃĽ Ã ı # H anna PH Â ī ÃĽ Â Ŀ Ġ( S OU D EL OR ) ĠTR OP ICAL ĠCY CL ONE : ĠWARNING ĠIS SU ED ĠAT Ġ5 : 00 ĠPM Ġ06 ... Ġhttp :// t . co / t H h j J w</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ320 Ġ[ IR ] ĠIC EM O ON Ġ[ AF T ERS H OCK ] Ġ| Ġhttp :// t . co / v AM 5 PO d Gy w Ġ| Ġ@ dj ic em oon Ġ| Ġ# Dub step Ġ# T rap Music Ġ# D n B Ġ# ED M Ġ# D ance Ġ# I ces Â ī ÃĽ _ Ġhttp :// t . co / z EV ak</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ320 Ġ[ IR ] ĠIC EM O ON Ġ[ AF T ERS H OCK ] Ġ| Ġhttp :// t . co / TH yz OM VW U 0 Ġ| Ġ@ dj ic em oon Ġ| Ġ# Dub step Ġ# T rap Music Ġ# D n B Ġ# ED M Ġ# D ance Ġ# I ces Â ī ÃĽ _ Ġhttp :// t . co / 83 j OO 0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ġ320 Ġ[ IR ] ĠIC EM O ON Ġ[ AF T ERS H OCK ] Ġ| Ġhttp :// t . co / TH yz OM VW U 0 Ġ| Ġ@ dj ic em oon Ġ| Ġ# Dub step Ġ# T rap Music Ġ# D n B Ġ# ED M Ġ# D ance Ġ# I ces Â ī ÃĽ _ Ġhttp :// t . co / 83 j OO 0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyMRIH6QMdeY",
        "colab_type": "code",
        "outputId": "614c00bb-d995-4ebe-9c50-d77e5c0c7425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LukStWjEMda9",
        "colab_type": "code",
        "outputId": "f0ddc477-ecd9-49c3-d145-e0e1a5f52b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape:', test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape: torch.Size([64, 86])\n",
            "tensor([[    0,   479,    35,  ...,   306,   571,     2],\n",
            "        [    0, 21947,   646,  ...,     1,     1,     1],\n",
            "        [    0, 21947,   646,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   128, 14696,  ...,     1,     1,     1],\n",
            "        [    0, 14826,   787,  ...,     1,     1,     1],\n",
            "        [    0,  5505, 23171,  ...,     1,     1,     1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh821MzDMdY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining our model architecture\n",
        "class CustomTransformerModel(nn.Module):\n",
        "  def __init__(self, transformer_model:PreTrainedModel):\n",
        "    super(CustomTransformerModel, self).__init__()\n",
        "    self.transformer = transformer_model\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None):\n",
        "    #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
        "\n",
        "    logits = self.transformer(input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "\n",
        "    return logits\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX2gGdhDMdVQ",
        "colab_type": "code",
        "outputId": "569756fb-d4aa-4c6b-e118-a068aad94670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 2\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wfGlMXHMdTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config=config)\n",
        "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model=transformer_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmFW0fi-MdPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch,\n",
        "                  custom_transformer_model,\n",
        "                  opt_func=CustomAdamW,\n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "#Show graph of learner states and metrics after epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "#Put learn in FP16 precession mode.--> Seems to not working\n",
        "if use_fp16:learner = learner.to_fp16\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYmmzE-EMdH6",
        "colab_type": "code",
        "outputId": "3b15af45-ce1d-4f57-8753-9c3ae03b63c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): RobertaForSequenceClassification(\n",
            "    (roberta): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (classifier): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3GYJVoFMdGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # For DistilBERT\n",
        "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
        "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n",
        "# For roberta-base\n",
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11],\n",
        "              learner.model.transformer.roberta.pooler]\n",
        "\n",
        "# # # For BERT\n",
        "# list_layers = [learner.model.transformer.bert.embeddings,\n",
        "#                learner.model.transformer.bert.transformer.layer[0],\n",
        "#                learner.model.transformer.bert.transformer.layer[1],\n",
        "#                learner.model.transformer.bert.transformer.layer[2],\n",
        "#                learner.model.transformer.bert.transformer.layer[3],\n",
        "#                learner.model.transformer.bert.transformer.layer[4],\n",
        "#                learner.model.transformer.bert.transformer.layer[5],\n",
        "#                learner.model.transformer.pre_classifier]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEnSXV0nKS-_",
        "colab_type": "code",
        "outputId": "0ace47c4-33ef-4a26-a588-47bc8802e17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.split(list_layers)\n",
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in', num_groups, 'groups')\n",
        "print(learner.layer_groups)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n",
            "[Sequential(\n",
            "  (0): Embedding(50265, 768, padding_idx=1)\n",
            "  (1): Embedding(514, 768, padding_idx=1)\n",
            "  (2): Embedding(1, 768)\n",
            "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
            "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
            "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=768, out_features=2, bias=True)\n",
            ")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeo6AyJCLUDZ",
        "colab_type": "text"
      },
      "source": [
        "####Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c2GSsrTKTFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('untrain')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Wb1evGKS7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('untrain');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_hd63qpKS5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVNEmDXtKS2z",
        "colab_type": "code",
        "outputId": "ffa15e36-6a82-471b-9c18-a5c76408d6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [86, 768]            38,603,520 False     \n",
              "______________________________________________________________________\n",
              "Embedding            [86, 768]            394,752    False     \n",
              "______________________________________________________________________\n",
              "Embedding            [86, 768]            768        False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 86, 86]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            590,592    False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 3072]           2,362,368  False     \n",
              "______________________________________________________________________\n",
              "Linear               [86, 768]            2,360,064  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [86, 768]            1,536      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [86, 768]            0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [2]                  1,538      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 125,237,762\n",
              "Total trainable params: 1,182,722\n",
              "Total non-trainable params: 124,055,040\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQYAl_D8KS0e",
        "colab_type": "code",
        "outputId": "1e1af6bd-7f77-4c81-ac34-4f77cbdcd69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='73' class='' max='107', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      68.22% [73/107 00:10<00:05 2.7401]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNBMv8VWKSyr",
        "colab_type": "code",
        "outputId": "8bb7efb9-10e2-426f-def7-246b5248af98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "learner.recorder.plot(skip_end=10, suggestion=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 3.31E-04\n",
            "Min loss divided by 10: 3.98E-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxddZ3/8dcna9OmadomLW3SfaVQ\nWmgoBQRk/YEKuCAWRUFG0Jkfoggz4+hvHH8wOirDMCoO8wOEiijI5oBYWWRfWrrve5suSbckbZJm\nT+79/P64N+1tepNuOUnuzfv5eJwHOed8z73ffLnN536X8znm7oiIiLSV0t0VEBGRnkkBQkRE4lKA\nEBGRuBQgREQkLgUIERGJK627K9BZ8vLyfPTo0d1dDRGRhLJ48eJyd8+Pdy5pAsTo0aNZtGhRd1dD\nRCShmNm29s5piElEROJSgBARkbgUIEREJC4FCBERiUsBQkRE4lKAEBGRuBQgREQkLgUIEZEE9tzi\nEp5asD2Q11aAEBFJYM8vLuGFJSWBvLYChIhIAttf18SArIxAXlsBQkQkgVXVNzOwb3ogr60AISKS\nwCrrmslVgBARkVgNzSHqm0Pk9tUQk4iIxKiqbwZQD0JERA5XWRcNEJqkFhGRWPvrmgD1IEREpI2D\nPQgFCBERiVV5sAehISYREYlRGZ2k1n0QIiJymMq6ZjJSU8hKTw3k9RUgREQSVGVdEwP6pmNmgby+\nAoSISIKqrAsuzQYoQIiIJKz9dU2B3QMBChAiIgmrqj64PEygACEikrCCTNQHChAiIglrf11TYPdA\ngAKEiEhCamgO0dgSVg9CREQOdzAPkyapRUQkVtB5mEABQkQkISlAiIhIXJUaYhIRkXgOJurrpx6E\niIjECPppcqAAISKSkCrrmshIS6FPenB/xhUgREQSUGuivqAyuULAAcLMrjSz9Wa2ycy+G+f8A2a2\nLLptMLPKmHM/M7PVZrbWzH5hQbaCiEiCCTpRH0BaUC9sZqnAr4DLgRJgoZm95O5rWsu4+50x5b8J\nnBn9+TzgfOCM6On3gYuAt4Oqr4hIIqkMOFEfBNuDmAlscvct7t4EPA1c20H5G4Cnoj870AfIADKB\ndGBPgHUVEUkoVQEn6oNgA0QBsCNmvyR67AhmNgoYA7wJ4O7zgLeAXdHtVXdfG+e628xskZktKisr\n6+Tqi4j0XF0xxNRTJqlnA8+5ewjAzMYDpwKFRILKJWZ2QduL3P1hdy9y96L8/PwurbCISHdx98gQ\nU4D3QECwAaIUGBGzXxg9Fs9sDg0vAXwGmO/uNe5eA/wFODeQWoqIJJj65hBNLeGE7kEsBCaY2Rgz\nyyASBF5qW8jMJgMDgXkxh7cDF5lZmpmlE5mgPmKISUSkN+qKPEwQYIBw9xbgduBVIn/cn3H31WZ2\nj5ldE1N0NvC0u3vMseeAzcBKYDmw3N3/FFRdRUQSSWuAGBhwgAhsmSuAu88F5rY59oM2+z+Mc10I\n+HqQdRMRSVStifoGJPAQk4iIBKArEvWBAoSISMLpiqfJgQKEiEjCSfhJahERCUZVfTN90lPok54a\n6PsoQIiIJJj9tcHfRQ0KECIiCacrEvWBAoSISMLpikR9oAAhIpJwuiJRHyhAiIgknMr65sDvgQAF\nCBGRhOLuVNY1BX4XNShAiIgklLqmEM0h1xyEiIgc7mCaDQUIERGJtb+2axL1gQKEiEhCqVIPQkRE\n4jmYqK+vehAiIhKjqxL1gQKEiEhCaR1iGpClACEiIjH21zaRlZ4aeCZXUIAQEUkolfXNXTJBDQoQ\nIiIJpbKumQFdMEENChAiIgmlsq6J3C6YfwAFCBGRhNJVifpAAUJEJKF0VaI+UIAQEUkYkUyuXfOw\nIFCAEBFJGLVNIVrCrlVMIiJyuNZEfV3xNDlQgBARSRitd1FriElERA7TlYn6QAFCRCRhdGWiPlCA\nEBFJGJUaYhIR6b32Vjfw6V99wIY9B444V6lJahGR3mvuyl0s21HJQ29vPuJcZX0z/TJSyUjrmj/d\nChAiIj3IG+v2AvDyip3srW447Nz+uqYum6AGBQgRkR6jprGFj7bs4/IpQ2kJO7/7aPth56vqmrvk\nQUGtAg0QZnalma03s01m9t045x8ws2XRbYOZVcacG2lmr5nZWjNbY2ajg6yriEh3e39jOU2hMH/z\nsTFcPGkIv/toG40toYPnuzJRHwQYIMwsFfgVcBUwBbjBzKbElnH3O919urtPB34JvBBz+gngPnc/\nFZgJ7A2qriIiPcGb6/aQ0yeNGaMGcvN5oymvaeLPK3YdPL+/rqnLJqgh2B7ETGCTu29x9ybgaeDa\nDsrfADwFEA0kae7+OoC717h7XYB1FRHpVuGw8+a6Mi6aNIT01BQumJDH+CHZPP7BVtwdiA4xddES\nVwg2QBQAO2L2S6LHjmBmo4AxwJvRQxOBSjN7wcyWmtl90R5J2+tuM7NFZraorKysk6svItJ1VpZW\nUV7TyKWThwBgZtx83mhWllaxeNv+SCbXLnzcKPScSerZwHPu3jrYlgZcANwNnA2MBW5ue5G7P+zu\nRe5elJ+f31V1FRHpdG+s20uKwUUTD/0t++xZBeT0SePxD7dyoLGFUNiTZoipFBgRs18YPRbPbKLD\nS1ElwLLo8FQL8D/AWYHUUkSkB3hz3R5mjBrIwH6HAkDfjDRmzxzJK6t2s3ZnNdB1d1FDsAFiITDB\nzMaYWQaRIPBS20JmNhkYCMxrc22umbWG0kuANQHWVUSk2+yuamBVaTWXTB56xLkvzxqFu/PgW5uA\nrkvUBwEGiOg3/9uBV4G1wDPuvtrM7jGza2KKzgae9tZZmMi1ISLDS2+Y2UrAgEeCqquISHd6a31k\nkealpw454tyIQX25fMpQ3ttYDnRtDyItyBd397nA3DbHftBm/4ftXPs6cEZglRMR6SHeWLuXwoFZ\nTBiSHff8V88fw6ur9wD0yklqEZFeqaE5xAebyrl08hDMLG6Zc8YMYvIp/QEYkCST1CIichTztlRQ\n3xziklOPnH9oZWbcfcUkZo0dxKB+XRcgAh1iEhGRjr2xdg99M1I5Z8ygDstdNmUol01pP4gEQT0I\nEZFu4u68uXYvHxufR5/0I+4F7nYKECIi3WTd7gPsrGqIu3qpJ1CAEBHpJm9Gn/1w8SQFCBERifHG\n2j2cUTiAITl9ursqcSlAiIh0g+ZQmOUlVZw/Pq+7q9IuBQgRkW6wY18dobAzLj/+zXE9gQKEiEg3\n2FpRC8CYvH7dXJP2KUCIiHSDLWWRADFWAUJERGIVl9cyICv9sPTePc0xBQgzG2dmmdGfP25md5hZ\nbrBVExFJXlsranv08BIcew/ieSBkZuOBh4k8COj3gdVKRCTJFZfV9ujhJTj2ABGOPt/hM8Av3f3v\ngWHBVUtEJHnVN4XYWdXA6CQJEM1mdgNwE/By9FjXJSUXEUki2/b1/BVMcOwB4qvAucCP3L3YzMYA\nvw2uWiIiyau4LDECxDGl+3b3NcAdAGY2EOjv7j8NsmIiIslqS3kkQCTFEJOZvW1mOWY2CFgCPGJm\n/xFs1UREktPW8lqG9M8kO7NnP5LnWIeYBrh7NfBZ4Al3Pwe4LLhqiYgkr+Ly2h7fe4BjDxBpZjYM\nuJ5Dk9QiInICist7/hJXOPYAcQ/wKrDZ3Rea2VhgY3DVEhFJTlX1zVTUNvX4CWo49knqZ4FnY/a3\nAJ8LqlIiIslqa4JMUMOxT1IXmtkfzWxvdHvezAqDrpyISLIpLu/5SfpaHesQ0+PAS8Dw6Pan6DER\nETkOxeW1mMHIwX27uypHdawBIt/dH3f3lug2B8gPsF4iIkmpuLyWgtwsMtNSu7sqR3WsAaLCzG40\ns9TodiNQEWTFRESSUXF5z8/i2upYA8QtRJa47gZ2AdcBNwdUJxGRpOTubE2QJa5wjAHC3be5+zXu\nnu/uQ9z902gVk4jIcSmvaeJAY0tCrGCCk3ui3Hc6rRYiIr1A6wqmZBtiisc6rRYiIklgx746Hnp7\nM+Gwxz2/9eAS1+yurNYJO5kAEb8FRER6qWcW7eCnr6xj/pb4a3i2lNeSnmoMz+3TxTU7MR3eSW1m\nB4gfCAzICqRGIiIJat3uAwA8u7iE88bnHXG+uLyGkYP6kpZ6Mt/Nu06HtXT3/u6eE2fr7+49O0+t\niEgXW7e7GoC5K3dR3dB8xPmt5XWMSZDhJTi5ISYREYmqaWxhx756Ljt1CI0tYV5evuuw8+GwU1xR\ny5i8nn8HdatAA4SZXWlm681sk5l9N875B8xsWXTbYGaVbc7nmFmJmT0YZD1FRE7Whj2R4aXri0Yw\nYUg2zy7ecdj5nVX1NLWE1YMAMLNU4FfAVcAU4AYzmxJbxt3vdPfp7j4d+CXwQpuXuRd4N6g6ioh0\nlvXR+YdTh+VwfdEIlm6vZNPeAwfPby2vAxJniSsE24OYCWxy9y3u3gQ8DVzbQfkbgKdad8xsBjAU\neC3AOoqIdIr1uw/QLyOVgtwsPn1mAakpxrOLSg6eLy6vARQgWhUAsX2skuixI5jZKGAM8GZ0PwW4\nH7i7ozcws9vMbJGZLSorK+uUSouInIi1u6qZeEp/UlKM/P6ZXDJ5CM8vKaU5FAYiS1yz0lMZmpPZ\nzTU9dj1lkno28Jy7h6L7fwfMdfeSDq7B3R929yJ3L8rPV3JZEeke7s76PQeYfEr/g8c+P6OQ8ppG\n3lkf+fK6NfocarPEucc4yABRCoyI2S+MHotnNjHDS8C5wO1mthX4d+ArZvaTICopInKy9h5opLKu\nmUlDDwWIiycPIS874+BkdaI8hzpWkAFiITDBzMaYWQaRIPBS20JmNhkYCMxrPebuX3L3ke4+msgw\n0xPufsQqKBGRnqD1BrnJw3IOHktPTeEzZxbwxtq97KluYMf++oSaf4AAA4S7twC3A68Ca4Fn3H21\nmd1jZtfEFJ0NPO3uSt0hIglp3a7IDXKxQ0wAny8aQUvY+cUbGwmFPWGyuLYK9G5od58LzG1z7Adt\n9n94lNeYA8zp5KqJiHSa9bsPMDQnk9y+GYcdnzi0P9NG5PKHhZFhJvUgRER6mXW7DzDplJy45z4/\no5CWaHZXzUGIiPQiLaEwm8pqOLXN8FKrq6cNJzMthQFZ6QzslxG3TE+lhHsiIidha0UtTS1hJrUT\nIAZkpXPjrFHsq23q4pqdPAUIEZGTsHZXZAVTewEC4J8/NaXdcz2ZhphERDpw78treGXVrnbPr999\ngNQUY/yQxEnCd6wUIERE2lHd0Myv3y/mZ6+sp72V+Ot2H2BsXj8y01K7uHbBU4AQEWnHih1VQCSP\n0sKt++OWWb+nusPhpUSmACEi0o7lJZFH1PTLSOXphduPON/6kKC2N8glCwUIEZF2LNtRydi8fnz6\nzALmrtxFVf3hjxFtfQZEe/dAJDoFCBGRONydZTsqmTYil9lnj6ShOcxLy3ceVqY1QKgHISLSi+yq\naqDsQCPTR+RyekEOU4bl8PSCw4eZ1u+uJjszjcKBWd1Uy2ApQIiIxLF8R2T+YdqIXMyM2TNHsHpn\nNatKqw6WWbf7ABOHZifUMx6OhwKEiEgcy0oqSU81Th0WGT66dnoBmWkpByer3b3DHEzJQAFCRCSO\n5TsqmTIs5+D9DQOy0vnk1GG8uHQn9U0h9lQ3UlXffDCAJCMFCBGRNkJhZ2VJFdNH5B52/Atnj+BA\nYwtzV+5i3e7IMyBinyKXbBQgRETa2LS3htqmENPaBIiZYwYxJq8ff1i4I2YFU/IOMSlZn4hIG7ET\n1LHMjC+cPYKf/GUdjaEwp+T0YUDf9O6oYpdQD0JEpI1lJZX075PGmMFHPuDnc2cVkpZiLN9RmbQp\nNlopQIhIr9ISCrO9oq7DMsu2VzJ9RC4pKUcuX83vn8llpw4FYHIST1CDAoSI9DLPLS7h4//+1sFJ\n5rbqm0Ks33OAaYW5cc8DfGHmCACmDEve+QdQgBCRXmbelgrCDg+/uyXu+dU7qwiF/Yj5h1gfn5jP\nE7fM5BNThwVVzR5BAUJEepUl2/djBi8t28muqvojzi87OEE9oN3XMDMunJhPempy/wlN7t9ORCRG\n2YFGduyr5yuzRuHAY+8XH1Fm2Y5KCnKzGNK/T9dXsIdRgBCRXmPJ9shDf66ZXsAnpg7jqQU7qG44\nPIX38pLKDnsPvYkChIj0Gku27ycjNYXTC3L4+oVjqWls4fcfHcrQWlET6WF0NEHdmyhAiEivsXRb\nJacVRPIrnV4wgPPGDebxD4ppagkDsKIkkqm1bYqN3koBQkR6haaWMMtLKjlr5MCDx75+0Tj2VDfy\n4rJSAJbuqCTF4PQCDTGBAoSI9BJrd1XT2BI+LEBcOCGPyaf055H3thAOO8t3VDJxaH/6ZSoLEShA\niEgv0TpBfdaoQ8NHZsZtF45lw54a3lq/NzJBrfmHgxQgRKRXWLK9kmED+jBswOGPB7162nCGDejD\nv/55LZV1zUwfqQDRSgFCRHqFJdv2Hza81Co9NYVbzh9DcXktgHoQMRQgRCTp7a1uoLSynjPb6R3M\nnjmC/plp9ElPYeLQ7C6uXc+lmRgRSXqH5h+O7EEA9O+Tzvc/eSo7qxpIS/L0GcdDAUJEkt6S7ZVk\npKZw2vD2s6/OnjmyC2uUGBQqRSTpLdm2n9OjN8jJsQs0QJjZlWa23sw2mdl345x/wMyWRbcNZlYZ\nPT7dzOaZ2WozW2FmXwiyniKSvJpawqworYo7QS0dC2yIycxSgV8BlwMlwEIze8nd17SWcfc7Y8p/\nEzgzulsHfMXdN5rZcGCxmb3q7pVB1VdEktOaXdU0tYTbnX+Q9gXZg5gJbHL3Le7eBDwNXNtB+RuA\npwDcfYO7b4z+vBPYC+QHWFcRSVJLtkUnqNWDOG5BBogCYEfMfkn02BHMbBQwBngzzrmZQAawOc65\n28xskZktKisr65RKi0hyWbJ9P8MH9OGUAXq+w/HqKZPUs4Hn3D0Ue9DMhgG/Bb7q7uG2F7n7w+5e\n5O5F+fnqYIjIkZZur+RMDS+dkCADRCkwIma/MHosntlEh5damVkO8Gfg++4+P5AaikhS2xO9QU7D\nSycmyACxEJhgZmPMLINIEHipbSEzmwwMBObFHMsA/gg84e7PBVhHEUlih+YflD7jRAQWINy9Bbgd\neBVYCzzj7qvN7B4zuyam6GzgaXf3mGPXAxcCN8csg50eVF1FJDkt2b6fjLQUThuu5zuciEDvpHb3\nucDcNsd+0Gb/h3GuexJ4Msi6iUhiCYWdH89dy+qdVXzjonFcNDEfM+vwmsXb9jO1YAAZaT1lujWx\nqNVEpMdraA7xt08u5tfvF7NhTw03P76Qzz70Ie9sKOPwwYeIllCYJdv3s2pnNTM0QX3ClItJRHq0\nyromvvabRSzevp8fXj2FL54zimcX7+BXb27ipscWcNbIXL512UQG98tg3uYK5m2pYEHxPmoaW0gx\nuGiiVjieKIsXfRNRUVGRL1q0qLurISKdqLSynpseW8D2ijoe+MJ0PnnGsIPnGltCPLuohP96axM7\nqxoOHh+b34/zxg3m3LF5zBo7iMHZmd1R9YRhZovdvSjeOfUgRKRHWrurmpsfX0BdU4gn/mYms8YO\nPux8ZloqN84axeeLCvnzil2Ywblj83RDXCdSgBCRHmVreS0vLd/JI+9uoV9mGs9+41wmn9J+mu7M\ntFQ+e1ZhF9aw91CAEJFut6e6gT8t38mflu9keUkVAOePH8x9101jeG7WUa6WoChAiEi3Wb2zip/8\nZR3vbyrHHU4vyOF7n5jMp84YrsDQAyhABMjd+XBzBVMLB5DTJ/2o5f+4tIS5K3eTakZqqpGWYqSm\nRP47qF8mIwf1PbgNy+1Duh6NKAmqtrGF//zrBh77YCu5WenccckErpk+nHH5eh50T6IAEaA/Li3l\nO88sZ/yQbB676WxGDu4bt5y78/M3NvKff91I4cAs+mWk0RIOEwo7IXdaQk5FTRNNoUP5ClNTjILc\nLK4vKuSr54+hX6b+V0pi+OuaPfzgxVXsrGrghpkj+McrJ5PbN6O7qyVxaJlrQHZV1XPFA+9SkJvF\nrqoGUlOMh788g6LRgw4rFwo7//ziKn7/0Xaum1HIv312atyeQSjs7KluYPu+Orbvq2PHvjqW7ajk\nvY3lDO6Xwd9+fBw3zhpFn/STe6RiOOxU1TdT3dBM4cC+pKZ0fKeqyLHaXdXAD19azSurdzNxaDY/\n/szUI/49SNfraJmrAkQA3J2bHl/IwuJ9/OVbF+DALXMWUrq/np9eN5XPnBlZcdHQHOKOp5by2po9\n/O+Lx3H3FZOOmjqgraXb93P/axt4f1M5p+T04Y5LJ/D5osJjGn7aVlHLnA+3snFPDeU1jVTUNrGv\ntolQOPKZyO2bzsfG53HhxHwumpjP0BwtH5QTs72ijs8+9CEHGpq549IJ3HrBWKW/6CEUILrY7z/a\nzvf+uJJ7rz2NL587GojcDfqNJxczf8s+vnnJeG45fwy3PtF6d+hp3HTe6JN6zw83l/Pvr65nyfZK\nCgdmcc204Vx1+jBOL8g5IuisKq3iv9/ZzNyVu0hLSeG0ghzysjMZ3C+DwdkZDO6XSVZGKou37efd\nDWXsPdAIwKSh/fn4pHyunjac04Yf+boi8ZTXNHLdQx9SWd/MM18/l4lD+3d3lSSGAkQX2l5Rx5U/\nf5ezRg7kiVtmkhIzRNPUEub//M9KnllUQv/MNBpbwkfcHXoy3J2315fx6/eLmbelglDYKRyYxVWn\nn8JVU4fR0Bziobc3897GcrIz07hx1ihuOX80QzroGbg763Yf4N0NZby7sYwFxftoDjnj8vtx7fQC\nrpk2nNF5/Tql/pJ8ahtb+OIj81m/5wC/+9os5UXqgRQgukg47Mx+ZD5rd1bzyp0XUhBnmZ6788h7\nW/jt/G387HPTOHfc4DivdPL21zbx+po9/GXVLt7fVE5zKPL/OS87k1s+NpovnTOKAVlHX1nVVmVd\nE39ZtZsXl5XyUfE+3GHaiFw+OfUULpo4hIlDs9WzEACaQ2G+9ptFvLexjIe/XMRlU4Z2d5UkDgWI\nLvLr94u59+U13HfdGXy+aMTRL+giVfXNvLVuLy1h51NnDDvpiexWOyvreXnFTl5ctpPVO6sBGNI/\nkwsm5HPhxDw+Nj5PeXB6KXfnrmeX88KSUn7y2anMnjmyu6sk7VCA6AKb9tbwyV+8xwUT8njkK0W9\n7lv0zsp63t9Yzjsby/hgUzmVdc2YRXosedmZ5PfPJC87g/zsTIbk9OGskbmcUZirVVJJ6qevrOOh\ntzdz52UT+dZlE7q7OtIBJevrQHVDM1f/8n1y+qSTk5UW+W/05+G5WXzxnJFkpnX8jXt/bRN3PLWU\nrIxUfvzZqb0uOAAMz83i+rNHcP3ZIwiFnZWlVXywqZztFXWU1zRSXtPI5r01lB1oPHg/R06fNM4b\nl8f5E/K4YHweowb37ZVtl2yeWrCdh97ezBfPGckdl47v7urISej1ASIcdqaPyKW6vpnqhhb2VtdQ\n3dBMdX0L9c0h/rJqNw9/eUa7N/LsPdDAlx9dQHFFLf/vyzMY0l9LQVNTjOkjcpk+4sjnALs7ZTWN\nzN+yjw82lvP+pnJeWb0biKRp/vZlE/nU1GGHTe5L4ijZX8e9L6/hggl53Hvt6Qr4CU5DTB14aflO\n7n5mOYWDsphz88wj7oQu2V/HjY9+xJ7qRh69qYjzx+d16vv3Bu7O1oo63t9Yxu8X7GDtrmqmFQ7g\nu1ed2ikT+HurG/jPNzayblc1/60AHih356tzFrKgeB+v3XkhhQPjZw6QnkVzECdhQfE+bn1iEemp\nxqM3nX3wW3FxeS1femQ+BxpbmPPVs5kxSneEnqxQ2PmfpaXc/9p6dlY1cOnkIfzjVZNPaN38gYZm\nHn53C4++V0xLOEyKGROGZvOH285VWpKAvLislG89vYx/uXoKXz1/THdXR46RAsRJ2lxWw82PL6Ds\nQCM/n30mowb35cZHFxB254lbZnJ6wYBA3re3amgO8fgHW/mvtzZR29RC0ahB9MlIJSPVSE9NObgN\nzclk9OB+jM7rx+i8vuRnZ9Iccn730TZ++eYm9tU2cfW04dx9xUQ2l9Xwtd8s4oIJ+Tx6U5ESHXay\nfbVNXPYf7zByUF+e/9vztPgggShAdILymkb+5jeLWFFSSb+MNLIz03jya+cwfoiyTwZlX20TD729\nieU7qmgOh2kOhWlucZpDYRpbwuypbqAlfOjz2y8jlT7pqVTUNnHeuMF896rJnFF4aB7kqQXb+acX\nVnJ9USE//dwZPWJ8PBx23tlQxnsby7l62jDOHJmYN5J95w/LeGn5Tv58xwVMOkV3SicSrWLqBHnZ\nmTx96yzufm4563ZVM+erMxkxSGOsQRrUL4Pvf3JKu+dbQmFKK+spLq9lW0UdxeW1VNQ2cd2MQi6c\nkHdEALhh5kh2Vdbzizc3MTw3i29fNvGI16ysa+Kt9XuZNXYwwwYE9zyChuYQf1xayq/fL2bT3hrM\n4LEPirl4Uj53Xj7xsMDW0729fi8vLC3ljkvGKzgkGfUgToC794hvn3L83J27n13B80tK+NnnzuD6\ns0dQ3xTir2v38OKynbyzYS/NIacgN4unb5vV6V8Cymsa+e28bTw5fxsVtU1MGZbDrReO4eJJQ/jd\nR9t55L0tVNY1c9mpQ/n2ZROOa/iyoTlEXVMo0tMKhWkOOS3R3lZkqXFT5L8HIsuOh+T04c7LJpKV\nceI3TtY2tnDFA+/SJz2Fud+64KhLwqXn0RCTSIzmUJhb5izkw80VXDFlKO9uKKO2KcTQnEyumTac\n6SMG8r0/riQ7M63TgoS784eFO7jn5TXUNYW4dPIQvnbBWGaNHXTYl40DDc3M+WArj7y3heqGFi6K\nZtI9d9xgJg3tf8Ty352V9by+Zg+vr9nD/C0Vhw25tScrPZXB2RmUVtYzaWh/Hv5yESMrd8H998OT\nT0JNDWRnw403wl13wbhx7b7WPX9aw2MfFPPsN87lbKXuTkgKECJt1DS2cMPD89lWUcsnpg7jmunD\nOWfM4IOTq6tKq/jSox91GCS2VdTyb3PXsW53NV85dzRfPGdk3DQmFTWN/OPzK/nr2j2cN24w91x7\n+lHnrqrqm3n8g2JeWFLK9nLtvcAAAAsuSURBVH11AAzsm845YwZz7rjBVNU389qa3awqjaQ4GZvf\nj8tPHcrw3CzSUo30lBTS04y0lBQy0lLIy844eFd76yqut9fv5VtPL+P8jQv55Qs/IrWlBZqbD1Ui\nPT2yPfccXHXVEXV8a/1ebpmzkC+dM5J//fTUY2t46XEUIETiaAmFcWh3RVN7QeJAQzMPvrmJxz/Y\nSlqqMemU/izdXsnQnExuv3g815894uBQy5vr9vAPz62kur6Zf7hyErecP+a4bwIsraxn3uYK5m2u\nYP6WCkor6zGDM0fkcvmUU7h8ytATXiyxc9EqBp1/Nn2aGtov1LcvrFhxWE/i9x9t559fXMXEof35\nw9dnHdMjdaVnUoAQOUGxQeL3t57Dh5sruP+19ZTXRCbD/+F/TWJITh8+3FzOf7y2gUXb9lOQm8Xt\nl4xn9c4qnpy/ncmn9Oc/Z09n8ik5J10fd6dkfz190lPJ798JiRD/7u/wRx/FYnsObaWnw223wYMP\nEg47P3t1Pf/9zmY+PimfB794Ftm6ryShKUCInITWIFHT2EIo7BSNGsi/XH0aUwsPn0B2d97bWM79\nr29g+Y5KAG69YAx3XTGp0zLodrqcHDhw4JjKNZTv465nl/PnFbv40jkj+b/XnEaa7idJeAoQIidp\nVWkV9726ns8XFfLJqcM6XMXm7ry7sZx+Gak9/5nLKSlwDH8D3IzrfvU+i7ft53ufmMytF4zVSr4k\nofsgRE7S6QUD+M0tM4+prJlx0cT8gGvUSbKzj6kHUZOexarSKv7rS2fxiamd8wRE6fnUPxTpzW68\nMTLH0IFwWhqrLrmap2+bpeDQyyhAiPRmd9111ACRkpHBuQ/+KGHTgMiJU4AQ6c3GjYvc59C375GB\nIj09cvy55zq8WU6SV6ABwsyuNLP1ZrbJzL4b5/wDZrYsum0ws8qYczeZ2cbodlOQ9RTp1a66KnKf\nw223RVY1paRE/nvbbZHjcW6Sk94hsFVMZpYKbAAuB0qAhcAN7r6mnfLfBM5091vMbBCwCCgCHFgM\nzHD3/e29n1YxiYgcv45WMQXZg5gJbHL3Le7eBDwNXNtB+RuAp6I//y/gdXffFw0KrwNXBlhXERFp\nI8gAUQDsiNkviR47gpmNAsYAbx7PtWZ2m5ktMrNFZWVlnVJpERGJ6CmT1LOB59w9dDwXufvD7l7k\n7kX5+Qmy7lxEJEEEGSBKgREx+4XRY/HM5tDw0vFeKyIiAQgyQCwEJpjZGDPLIBIEXmpbyMwmAwOB\neTGHXwWuMLOBZjYQuCJ6TEREukhgqTbcvcXMbifyhz0VeMzdV5vZPcAid28NFrOBpz1mOZW77zOz\ne4kEGYB73H1fR++3ePHi8ugy2ap2igxo51y8422PdbSfB5R3VLcT1F59T6Z8R2USqX2Ot22O9ZrO\naJ+jtVfb88ncPj3xs9NevTrjmkRtn1HtnnH3pNmAh4/3XLzjbY91tE8k2HXp73Ki5ZOlfY63bbqy\nfY7WXnHKJ2379MTPjtrn+LaeMkndWf50AufiHW977Gj7QTje9ziW8snSPify+l3VPkdrr5742TnW\na463fXriZ+dE36M3tc9BSZPuu7uY2SJv5yYTUfscjdqnfWqbjnVF+yRbD6I7PNzdFejh1D4dU/u0\nT23TscDbRz0IERGJSz0IERGJSwFCRETiUoCIYWaPmdleM1t1AtfOMLOV0dTmv7CYB/aa2TfNbJ2Z\nrTazn3VurbtOEO1jZj80s9KYtO+f6PyaBy+oz070/F1m5maW13k17loBfXbuNbMV0c/Na2Y2vPNr\n3jUCap/7on93VpjZH80s93hfWwHicHM48ayxDwG3AhOi25UAZnYxkSy209z9NODfT76a3WYOndw+\nUQ+4+/ToNvfkqtht5hBA25jZCCKZBLafZP262xw6v33uc/cz3H068DLwg5OtZDeaQ+e3z+vA6e5+\nBpFHL/zT8b6wAkQMd38XOOyObTMbZ2avmNliM3svmhqENmWGATnuPt8js/5PAJ+Onv5b4Cfu3hh9\nj73B/hbBCah9kkKAbfMA8A9EnouSsIJoH3evjinajwRuo4Da5zV3b4kWnU8kp91xUYA4uoeBb7r7\nDOBu4L/ilCkgkpK8VWx68onABWb2kZm9Y2ZnB1rbrney7QNwe7Qb/Fg091ayOKm2MbNrgVJ3Xx50\nRbvJSX92zOxHZrYD+BKJ3YOIpzP+bbW6BfjL8VYgsFxMycDMsoHzgGdjhoUzj/Nl0oBBwCzgbOAZ\nMxvrSbC+uJPa5yHgXiLf/u4F7ifyYU5oJ9s2ZtYX+B6R4aWk00mfHdz9+8D3zeyfgNuBf+m0Snaj\nzmqf6Gt9H2gBfne81ypAdCwFqIyOcR5kkcepLo7uvkTkj1xs9y02PXkJ8EI0ICwwszCRJFvJ8ISj\nk24fd98Tc90jRMaSk8HJts04Ig/RWh79A1EILDGzme6+O+C6d4XO+LcV63fAXJIkQNBJ7WNmNwOf\nAi49oS+lQSd7SrQNGA2sitn/EPh89GcjMtkc77oFRHoJRqQr94no8W8QyUYLkeGmHURvUEzELYD2\nGRZT5k4imX27/ffsCW3TpsxWIK+7f8ee1D7AhJgy3yTy0LFu/z17UPtcCawB8k+4Tt3dKD1pI/LQ\nol1AM5Fv/n9D5FvcK8DyaGP/oJ1ri4BVwGbgwdYgAGQAT0bPLQEu6e7fs4e1z2+BlcAKIt+IhnXV\n79PT26ZNmYQOEAF9dp6PHl9BJIldQXf/nj2sfTYR+UK6LLr99/HWS6k2REQkLq1iEhGRuBQgREQk\nLgUIERGJSwFCRETiUoAQEZG4FCAkqZlZTRe/36NmNqWTXisUzVS6ysz+dLRsnGaWa2Z/1xnvLQJ6\nopwkOTOrcffsTny9ND+UAC1QsXU3s98AG9z9Rx2UHw287O6nd0X9JPmpByG9jpnlm9nzZrYwup0f\nPT7TzOaZ2VIz+9DMJkWP32xmL5nZm8AbZvZxM3vbzJ6L5tv/XUwO/rfNrCj6c000mdxyM5tvZkOj\nx8dF91ea2b8eYy9nHoeS+GWb2RtmtiT6GtdGy/wEGBftddwXLfv30d9xhZn9305sRukFFCCkN/o5\nkWdQnA18Dng0enwdcIG7n0kkM+iPY645C7jO3S+K7p8JfBuYAowFzo/zPv2A+e4+DXiXSM7+1vf/\nubtP5fBMnHFF8+9cSuROc4AG4DPufhZwMXB/NEB9F9jskedq/L2ZXUHk+QAzgenADDO78GjvJ9JK\nyfqkN7oMmBKTJTMnmj1zAPAbM5tAJLtsesw1r7t7bL7+Be5eAmBmy4jk0Xm/zfs0cSj54GLg8ujP\n53LomQ+/p/2HSGVFX7sAWEvkATAQybnz4+gf+3D0/NA4118R3ZZG97OJBIx323k/kcMoQEhvlALM\ncveG2INm9iDwlrt/Jjqe/3bM6do2r9EY83OI+P+Wmv3QJF97ZTpS7+7To6m/XwX+N/ALIs8+yAdm\nuHuzmW0F+sS53oB/c/f/d5zvKwJoiEl6p9eIZP8EwMxaUyoP4FCq5JsDfP/5RIa2AGYfrbC71wF3\nAHeZWRqReu6NBoeLgVHRogeA/jGXvgrcEu0dYWYFZjakk34H6QUUICTZ9TWzkpjtO0T+2BZFJ27X\nEEnJDvAz4N/MbCnB9q6/DXzHzFYA44Gqo13g7kuJZC29gcizD4rMbCXwFSJzJ7h7BfBBdFnsfe7+\nGpEhrHnRss9xeAAR6ZCWuYp0seiQUb27u5nNBm5w92uPdp1IV9MchEjXmwE8GF15VEkSPGJVkpN6\nECIiEpfmIEREJC4FCBERiUsBQkRE4lKAEBGRuBQgREQkrv8PuESjYpmu7qAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCWvtbrrKSwS",
        "colab_type": "code",
        "outputId": "15dcdbed-7201-4e48-e2d4-38f8369b3ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=2e-03, moms=(0.8, 0.7))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.587357</td>\n",
              "      <td>0.478331</td>\n",
              "      <td>0.766097</td>\n",
              "      <td>0.233903</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWmBEDjBKStp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('first_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "priyICWiKSrz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('first_cycle');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS7-3ihqKSpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-2)\n",
        "lr = 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ergad0KSni",
        "colab_type": "code",
        "outputId": "984f99e6-e9ca-4c6a-ed18-385c4e1cf628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.480170</td>\n",
              "      <td>0.422294</td>\n",
              "      <td>0.821288</td>\n",
              "      <td>0.178712</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUKCLiATE/wdOHXz9exFwigAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0HGEQDsKSkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('second_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoe9EdFrKSfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('second_cycle');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUzfa8JcMdEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu8STlitMc73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "2ff36783-f55b-4dc0-cdd3-d8f25b7b5477"
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.443287</td>\n",
              "      <td>0.412014</td>\n",
              "      <td>0.827858</td>\n",
              "      <td>0.172142</td>\n",
              "      <td>00:25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbsO--9PMc5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('third_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPr_6j1NMcx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('third_cycle');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5j7Ahz5McvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--603jbKMctF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "d3610536-03fd-447d-aa66-4b24581c54c8"
      },
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.422472</td>\n",
              "      <td>0.396298</td>\n",
              "      <td>0.831800</td>\n",
              "      <td>0.168200</td>\n",
              "      <td>00:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.356796</td>\n",
              "      <td>0.389670</td>\n",
              "      <td>0.847569</td>\n",
              "      <td>0.152431</td>\n",
              "      <td>00:57</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEfEIBbqIiEco0EVEPOL/Aelsl2DCE2SrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}